---
title: "Vast Challenge Mini Challenge 2"
description: |
  A short description of the post.
author:
  - name: Linli Zhong
    url: https://github.com/LinliZhong
date: 07-23-2021
output:
  distill::distill_article: 
    toc: true
    toc_depth: 3
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.retina = 3,
                      echo = TRUE, message = FALSE, error = FALSE, 
                      warning = FALSE)
```

## 1. Overview
### 1.1 Background
GAStech is a natural gas production company in an island country of Kronos in the past twenty years. It builds strong relationships with the government of Kronos but low environment stewardship. In January 2014, when celebrating the success fortune by IPO (initial public offering), several employees of GAStech went missing. 

This post is focused on [VAST Challenge 2021 Mini-Challenge 2](https://vast-challenge.github.io/2021/MC2.html). Mini-Challenge 2 provides useful data of missing employees’ relevant information, a list of vehicle assignments by employee, vehicle tracking data, loyalty card transaction data, credit and debit card transaction data, and a tourist map of Abila. In this post, I will make use of R language to visual and analyze available data and identify the suspicious activity of the employees.

### 1.2 Literature review


## 2. Data Preparation
### 2.1 Install and load packages
The code chunk below is to check required packages are installed or not, if they are not installed, the code chunk will help install them automatically. After all packages are installed, the code chunk will load them.

```{r}
packages = c('igraph','ggraph','visNetwork','lubridate','dplyr',
             'clock','tidyverse','DataExplorer','gplots','plotly',
             'ggplot2','superheat','tm','plotly','lattice','GDAdata','raster',
             'sf','tmap','foreign','gifski','rgdal','tiff'
             )
for(p in packages){
  if(!require(p, character.only = T)){
  install.packages(p)
  }
  library(p,character.only = T)}
```

### 2.2 Import relevant data
The data is stored in MC2 file. Read_csv()is to import four csv files into R. "Windows-1252" is a single-byte character encoding of the Latin alphabet for value "Katerina’s Café".

```{r}
cc<- read_csv("MC2/cc_data.csv",locale = locale(encoding = "windows-1252"))
lyt<-read_csv("MC2/loyalty_data.csv",locale = locale(encoding = "windows-1252"))
gps <-read_csv("MC2/gps.csv")
car<-read_csv("MC2/car-assignments.csv")
```

### 2.3 Data preparation

**1. Change data type.** The code chunk below is to convert id in gps from number to factor, last4ccnum in cc from number to character and timestamp in gps, loyalty, and credit card from character data type to Datetime format.

```{R}
gps$id<-as.factor(gps$id)
car$CarID<-as.factor(car$CarID)
cc$last4ccnum<-as.character(cc$last4ccnum)
gps$Timestamp<-date_time_parse(gps$Timestamp,zone = "",format = "%m/%d/%Y %H:%M:%S")
lyt$timestamp<-date_time_parse(lyt$timestamp,zone = "",format = "%m/%d/%Y")
cc$timestamp<-date_time_parse(cc$timestamp,zone = "",format = "%m/%d/%Y %H:%M")
```

**2. Combine data.** The code chunk below is to combine first name and last name of employee together in the list of car.

```{r}
car$Name<-paste(car$FirstName,car$LastName)
```

**3. Add additional column.** When analyzing the car assignment csv file, we may notice that the GAStech does not assign specific company truck for each truck driver, but this is not a case for other employees with title which is not truck driver. Hence, we can divide missing employees into two types, one is general employees, another one is truck driver, to further investigate their suspicious activities. Besides, add additional column for car type, and there are two types of cars, one for company truck another one for company car.

```{r}
car$Category<-ifelse(car$CurrentEmploymentTitle == "Truck Driver", 
                       "Truck Driver","General Staff")
gps$car_type<-ifelse(gps$id %in% c('101','104','105','106','107'),'Company truck',
                     'company car')
```

The code chunk below is to extract day of the timestamp and add it in column called "day" in each file.

```{r}
cc$day<-get_day(cc$timestamp)
lyt$day<-get_day(lyt$timestamp)
gps$day<-get_day(gps$Timestamp)
```

## 3. MC2 Visualization Preparation
### 3.1 Question 1 

**Using just the credit and loyalty card data, identify the most popular locations, and when they are popular. What anomalies do you see? What corrections would you recommend to correct these anomalies? Please limit your answer to 8 images and 300 words.**

The code chunk below is to create bar chart to find out the popular location for both credit card and loyalty card.

```{r}
p1<-plot_ly(data = cc, x = ~location, marker = list(color = 'rgb(158,202,225)',
                           line = list(color = 'rgb(8,48,107)', width = 1.5)))
p1 <- p1 %>% layout(title = "Frequency of each location by credit card",
                                      xaxis = list(title = "",
                                                   tickfont = list(size = 10)),
                                      yaxis = list(title = "count",
                                                   tickfont = list(size = 10),
                                                   range = c(0,220)))

p2<-plot_ly(data = lyt, x = ~location, marker = list(color = 'rgb(158,202,225)',
                           line = list(color = 'rgb(8,48,107)', width = 1.5)))
p2 <- p2 %>% layout(title = "Frequency of each location by loyalty card",
                                      xaxis = list(title = "",
                                                   tickfont = list(size = 10)),
                                      yaxis = list(title = "count",
                                                   tickfont = list(size = 10),
                                                   range = c(0,220)))
p1
p2
```
From the chart above, the y axis stands for the frequency of the employees went to the stores. There are 4 locations have more than 150 transactions by credit card from January 6th to 19th. We can mark these 4 locations as popular locations. These four popular locations are *Katerina’s Café, Hippokampos, Guy's Gyros, and Brew've Been Served*. On top of that Katerina’s Café is the most popular location where these 44 missing employees like. 212 and 195 transactions were made by credit card and loyalty card in Katerina’s Café within 14 days. In average, there were around 15 transactions made by credit card per day in Katerina’s Café.

```{R}
cc1<-cc%>%
  filter(location == "Katerina’s Café"|
         location == "Hippokampos"|
         location == "Guy's Gyros"|
         location == "Brew've Been Served")
p2<-ggplot(data = cc1, aes(x=day, fill = location))+
  geom_bar() + scale_fill_brewer(palette="Accent")+
  ggtitle("Popular location by day")
ggplotly(p2)
```


```{r}
location_by_day <- cc1 %>%
        ggplot(aes(x = day, fill = location)) +
        geom_bar() +
        labs(title = "popular locations' transaction by day",
             x = "", y = "") +
        facet_wrap(~ location, ncol = 2, scales = "free_y")+
  scale_fill_brewer(palette="Accent")
location_by_day_plotly <- ggplotly(location_by_day) %>% 
        layout(yaxis = list(title = list(text = "Frequence", standoff = 20L)))

location_by_day_plotly<-location_by_day_plotly%>%
  layout(title = "Transaction frequency per location per day",
         xaxis = list(title = "",
                      tickfont = list(size = 10)),
                      yaxis = list(title = "count",
                      tickfont = list(size = 10)))
location_by_day_plotly
```

From the above bar chart, I conclude the insights below.

1.	Brew've Been Served had three popular days from 6th January to 19th January. These three days are 8th, 10th, and 15th. Meanwhile, it had the same number of transactions (count 17 transactions) by tracing the missing employees’ credit card and loyalty card in these three days. However, on 11th and 12th January, this store didn’t have any transactions with missing employees.

2.	Guy's Gyros had two popular days within 14 days on 9th and 13th of January with 15 transactions with missing employees. These two days are around three times of the day on 11th, 12th and 18th with 4, 5, and 6 transactions respectively.

3.	Hippokampos also had two popular days on 6th and 16th of January but with different transactions in these two days. on January 6th it received 16 transactions and on January 16th it received one more transaction compared with January 6th. From January 16th to 19th, the overall transaction declined, reaching a 14-day low on the 19th.

4.	Katerina’s Café, the most popular locations’ popular day was January 18th. It had 20 transactions in that day. But from 6th to 10th January, transaction volume in Katerina’s Café experienced substantially decrease to 11 transactions. Then jumped to 18 transactions and drop back to 11 transactions on January 12th. From 13th to 18th of January the number of transactions fluctuated steadily. On January 19th it plummeted to 9 transactions.

```{R}
cc2<-cc
# create breaks
breaks <- hour(hm("00:00", "5:59", "11:59", "17:59", "23:59"))
# labels for the breaks
labels <- c("Night", "Morning", "Afternoon", "Evening")
cc2$Time_of_day <- cut(x=hour(cc2$timestamp), breaks = breaks, labels = labels, include.lowest=TRUE)
cc2$date_time<-paste(cc2$day,cc2$Time_of_day)

p3<-ggplot(cc2, aes(date_time, location)) + 
  geom_bin2d() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
p3<-p3+scale_x_discrete(limits = c("6 Night", "6 Morning", "6 Afternoon","6 Evening",
                                   "7 Night", "7 Morning", "7 Afternoon","7 Evening",
                                   "8 Night", "8 Morning", "8 Afternoon","8 Evening",
                                   "9 Night", "9 Morning", "9 Afternoon","9 Evening",
                                   "10 Night", "10 Morning", "10 Afternoon","10 Evening",
                                   "11 Night", "11 Morning", "11 Afternoon","11 Evening",
                                   "12 Night", "12 Morning", "12 Afternoon","12 Evening",
                                   "13 Night", "13 Morning", "13 Afternoon","13 Evening",
                                   "14 Night", "14 Morning", "14 Afternoon","14 Evening",
                                   "15 Night", "15 Morning", "15 Afternoon","15 Evening",
                                   "16 Night", "16 Morning", "16 Afternoon","16 Evening",
                                   "17 Night", "17 Morning", "17 Afternoon","17 Evening",
                                   "18 Night", "18 Morning", "18 Afternoon","18 Evening",
                                   "19 Night", "19 Morning", "19 Afternoon","19 Evening"))
p3 <- ggplotly(p3)
p3 <- p3 %>% layout(autosize = F, width = 800, height = 500)
p3<-p3%>% layout(title = "Time of day vs location",
                                      xaxis = list(title = "",
                                                   tickfont = list(size = 8)),
                                      yaxis = list(title = "",
                                                   tickfont = list(size = 8)))

```

```{r fig.height = 5, fig.width = 5}
p3
```

**Anomalies:**

1.	Data anomalies: as I draw graphs, I noticed there are 1490 rows in credit card, while 1392 rows in loyalty card. The credit card cannot match loyalty card totally. So I only use credit card data to draw the heatmap above.
2.	Activity anomalies: 
a. Kronos Mart: have suspicious transaction data on January 12th 13th 19th night.
b. Jack’s Magical Beans: usually employees have daily morning transactions in this store, but no transactions on 11th, 12th, 18th, and 19th.
c. Daily Dealz: only has transactions on 13th night.
d. Carlyle Chemical Inc., Brewed Awakenings, Brew’ve Been Served, Bean There Done That didn’t have any transaction data on January 12th, 13th, 18th, and 19th.

### 3.2 Question 2 

**Add the vehicle data to your analysis of the credit and loyalty card data. How does your assessment of the anomalies in question 1 change based on this new data? What discrepancies between vehicle, credit, and loyalty card data do you find? Please limit your answer to 8 images and 500 words.**

The below code chunk is to visual the movement patter by company cars and company trucks, and they are faceted by employment type and truck car id respectively.
